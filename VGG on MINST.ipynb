{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: VGG on MINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the shape of new data and see that our images are 28×28 pixels, so we need to add a new axis, which will represent a number of channels. Also, it is important to do one-hot encoding of labels and normalization of input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(28, 28) image shape\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train[0].shape, 'image shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(28, 28, 1) image shape\n"
     ]
    }
   ],
   "source": [
    "# Add a new axis\n",
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_test = x_test[:, :, :, np.newaxis]\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train[0].shape, 'image shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,308,394\n",
      "Trainable params: 1,308,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define VGG\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, decay=1e-6)\n",
    "#model.compile(optimizer=adam, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.compile(adam, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a model, we need to train its parameters to make it powerful. Let’s train the model for a given number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the logs in a timestamped subdirectory\n",
    "# This allows to easy select different training runs\n",
    "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Specify the callback object\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
    "# We need to pass callback object to the fit method\n",
    "# The way to do this is by passing the list of callback objects, which is in our case just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/938 [..............................] - ETA: 0s - loss: 2.3027 - accuracy: 0.0781WARNING:tensorflow:From /Users/zhangmaoyu/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "938/938 [==============================] - 125s 133ms/step - loss: 0.7659 - accuracy: 0.7156 - val_loss: 0.5071 - val_accuracy: 0.8104\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.4293 - accuracy: 0.8428 - val_loss: 0.4141 - val_accuracy: 0.8419\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 126s 134ms/step - loss: 0.3432 - accuracy: 0.8728 - val_loss: 0.3473 - val_accuracy: 0.8695\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 125s 133ms/step - loss: 0.3054 - accuracy: 0.8882 - val_loss: 0.3106 - val_accuracy: 0.8839\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 128s 136ms/step - loss: 0.2790 - accuracy: 0.8968 - val_loss: 0.2982 - val_accuracy: 0.8901\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.2590 - accuracy: 0.9046 - val_loss: 0.2711 - val_accuracy: 0.9030\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 126s 134ms/step - loss: 0.2405 - accuracy: 0.9100 - val_loss: 0.2628 - val_accuracy: 0.9065\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.2258 - accuracy: 0.9174 - val_loss: 0.2547 - val_accuracy: 0.9059\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.2106 - accuracy: 0.9219 - val_loss: 0.2633 - val_accuracy: 0.9042\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.1969 - accuracy: 0.9263 - val_loss: 0.2569 - val_accuracy: 0.9087\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.1828 - accuracy: 0.9321 - val_loss: 0.2337 - val_accuracy: 0.9141\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 121s 128ms/step - loss: 0.1710 - accuracy: 0.9371 - val_loss: 0.2292 - val_accuracy: 0.9184\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 123s 131ms/step - loss: 0.1581 - accuracy: 0.9408 - val_loss: 0.2249 - val_accuracy: 0.9196\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.1442 - accuracy: 0.9465 - val_loss: 0.2444 - val_accuracy: 0.9134\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 128s 137ms/step - loss: 0.1347 - accuracy: 0.9498 - val_loss: 0.2321 - val_accuracy: 0.9232\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.1223 - accuracy: 0.9538 - val_loss: 0.2529 - val_accuracy: 0.9146\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 119s 127ms/step - loss: 0.1128 - accuracy: 0.9573 - val_loss: 0.2606 - val_accuracy: 0.9111\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.1005 - accuracy: 0.9622 - val_loss: 0.2649 - val_accuracy: 0.9206\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.0914 - accuracy: 0.9657 - val_loss: 0.2697 - val_accuracy: 0.9219\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.0824 - accuracy: 0.9689 - val_loss: 0.2769 - val_accuracy: 0.9160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac96f9f190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 30593), started 0:55:02 ago. (Use '!kill 30593' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f2fbd90587696d91\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f2fbd90587696d91\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it can be found that VGG performs very well on MINST data. Compared with Lenet, I think VGG will train better,since the training accuracy is up to 97%,and testing accuracy is about to 92%.and also I think the accuracy will be higher with the increase of the epoches,so that I hold the view that VGG performs better than Lenet on the MINST data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,we Train the model again with smaller learning rate to see the change of the loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model again with smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-5, decay=1e-6)\n",
    "model.compile(adam, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.2785 - val_accuracy: 0.9265\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 0.2872 - val_accuracy: 0.9263\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.3050 - val_accuracy: 0.9262\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 0.3157 - val_accuracy: 0.9254\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.3208 - val_accuracy: 0.9273\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.3350 - val_accuracy: 0.9250\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.3449 - val_accuracy: 0.9263\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 121s 129ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.3590 - val_accuracy: 0.9249\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.3657 - val_accuracy: 0.9245\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 122s 130ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.3800 - val_accuracy: 0.9259\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 123s 131ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.3947 - val_accuracy: 0.9250\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.3978 - val_accuracy: 0.9263\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.4118 - val_accuracy: 0.9252\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 126s 134ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.4209 - val_accuracy: 0.9262\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 129s 137ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.4379 - val_accuracy: 0.9252\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4509 - val_accuracy: 0.9251\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 126s 134ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.4626 - val_accuracy: 0.9267\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 124s 132ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.4727 - val_accuracy: 0.9249\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 127s 135ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.4771 - val_accuracy: 0.9265\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 127s 136ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.4983 - val_accuracy: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fac97694e80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 30593), started 1:43:09 ago. (Use '!kill 30593' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-471f357432d48ea5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-471f357432d48ea5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train the model again with smaller learning rate,We can achieve optimal accuracy much faster，and the training accuracy can almost up to 100%,and the testing accuracy is larger than the larger learning rate in the fisrt part,the training loss is become smaller, but the validation loss is much larger than  the larger learning rate in the fisrt part.At some point, I think there might be an overfitting situation. Therefore,we can conclude that the VGG with perfect hyper-parameter (which is a mannual process )can perform much better than Lenet on MINST data，However, we also need to pay attention to the possibility that the model may overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
