{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: VGG on cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from tensorflow.python.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test)=datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the shape of new data and see that our images are 32×32 pixels, so we need to add a new axis, which will represent a number of channels. Also, it is important to do one-hot encoding of labels and normalization of input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "(32, 32, 3) image shape\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_train[0].shape, 'image shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,702,186\n",
      "Trainable params: 1,702,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define VGG\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4, decay=1e-6)\n",
    "#model.compile(optimizer=adam, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "model.compile(adam, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a model, we need to train its parameters to make it powerful. Let’s train the model for a given number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the logs in a timestamped subdirectory\n",
    "# This allows to easy select different training runs\n",
    "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Specify the callback object\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
    "# We need to pass callback object to the fit method\n",
    "# The way to do this is by passing the list of callback objects, which is in our case just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/782 [..............................] - ETA: 0s - loss: 2.3030 - accuracy: 0.0781WARNING:tensorflow:From /Users/zhangmaoyu/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 1.7554 - accuracy: 0.3514 - val_loss: 1.4745 - val_accuracy: 0.4564\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 1.3810 - accuracy: 0.4998 - val_loss: 1.2891 - val_accuracy: 0.5390\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 1.2142 - accuracy: 0.5636 - val_loss: 1.1581 - val_accuracy: 0.5789\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 1.0925 - accuracy: 0.6098 - val_loss: 1.0953 - val_accuracy: 0.6118\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 1.0033 - accuracy: 0.6450 - val_loss: 1.0378 - val_accuracy: 0.6291\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 133s 170ms/step - loss: 0.9202 - accuracy: 0.6762 - val_loss: 0.9536 - val_accuracy: 0.6653\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 135s 172ms/step - loss: 0.8480 - accuracy: 0.7036 - val_loss: 0.9177 - val_accuracy: 0.6730\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 134s 172ms/step - loss: 0.7796 - accuracy: 0.7257 - val_loss: 0.9297 - val_accuracy: 0.6751\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.7100 - accuracy: 0.7532 - val_loss: 0.8625 - val_accuracy: 0.7005\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.6496 - accuracy: 0.7719 - val_loss: 0.8501 - val_accuracy: 0.7105\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.5799 - accuracy: 0.7977 - val_loss: 0.8134 - val_accuracy: 0.7206\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.5191 - accuracy: 0.8199 - val_loss: 0.8120 - val_accuracy: 0.7292\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 137s 176ms/step - loss: 0.4579 - accuracy: 0.8397 - val_loss: 0.8629 - val_accuracy: 0.7235\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.3904 - accuracy: 0.8637 - val_loss: 0.8733 - val_accuracy: 0.7290\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.3312 - accuracy: 0.8858 - val_loss: 0.8837 - val_accuracy: 0.7315\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.2695 - accuracy: 0.9065 - val_loss: 0.9602 - val_accuracy: 0.7235\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 145s 185ms/step - loss: 0.2186 - accuracy: 0.9234 - val_loss: 1.0006 - val_accuracy: 0.7360\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.1684 - accuracy: 0.9430 - val_loss: 1.0774 - val_accuracy: 0.7306\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 135s 172ms/step - loss: 0.1364 - accuracy: 0.9538 - val_loss: 1.2310 - val_accuracy: 0.7141\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 144s 184ms/step - loss: 0.1132 - accuracy: 0.9607 - val_loss: 1.2980 - val_accuracy: 0.7195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc07a1275b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 30593), started 2:37:14 ago. (Use '!kill 30593' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-46cd0880ce8a4661\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-46cd0880ce8a4661\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, it can be found that VGG performs better than Lenet on cifar10 data. Compared with Lenet, I think VGG will train better,since the training accuracy is up to 96% after 20 epoches,and testing accuracy is about to 70%,this is quite larger than that in Lenet whose testing accuraacy is only about to 50%. And also I think the accuracy will be higher with the increase of the epoches,so that I hold the view that VGG performs better than Lenet on the cifar10 data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,we Train the model again with smaller learning rate to see the change of the loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model again with smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-5, decay=1e-6)\n",
    "model.compile(adam, 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 144s 185ms/step - loss: 0.0292 - accuracy: 0.9947 - val_loss: 1.3202 - val_accuracy: 0.7463\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 145s 186ms/step - loss: 0.0126 - accuracy: 0.9988 - val_loss: 1.4140 - val_accuracy: 0.7493\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 1.4909 - val_accuracy: 0.7515\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.0053 - accuracy: 0.9997 - val_loss: 1.5836 - val_accuracy: 0.7489\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 1.6723 - val_accuracy: 0.7478\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 141s 181ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 1.7237 - val_accuracy: 0.7476\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7949 - val_accuracy: 0.7484\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8620 - val_accuracy: 0.7473\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 1.8783 - val_accuracy: 0.7412\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.8558 - val_accuracy: 0.7479\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 7.4516e-04 - accuracy: 1.0000 - val_loss: 1.8890 - val_accuracy: 0.7489\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 135s 172ms/step - loss: 5.8955e-04 - accuracy: 1.0000 - val_loss: 1.9257 - val_accuracy: 0.7473\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 4.8048e-04 - accuracy: 1.0000 - val_loss: 1.9582 - val_accuracy: 0.7488\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 2.1471 - val_accuracy: 0.7293\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 136s 173ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.9492 - val_accuracy: 0.7478\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 4.6442e-04 - accuracy: 1.0000 - val_loss: 1.9759 - val_accuracy: 0.7486\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 3.5476e-04 - accuracy: 1.0000 - val_loss: 2.0022 - val_accuracy: 0.7486\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 2.9742e-04 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.7491\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 2.4921e-04 - accuracy: 1.0000 - val_loss: 2.0717 - val_accuracy: 0.7473\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 2.0251e-04 - accuracy: 1.0000 - val_loss: 2.1071 - val_accuracy: 0.7478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc01077e910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 30593), started 3:26:57 ago. (Use '!kill 30593' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-85744f3e452753fc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-85744f3e452753fc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train the model again with smaller learning rate,We can achieve optimal accuracy much faster，and the training accuracy can almost up to 100%,and the testing accuracy is larger than the  1e-4 learning rate in the fisrt part,the training loss is become smaller, but the validation loss is much larger than  the 1e-4 learning rate in the fisrt part.At some point, I think there might be an overfitting situation. Therefore,we can conclude that the VGG with perfect hyper-parameter (which is a mannual process )can perform much better than Lenet on cifar10 data，However, we also need to pay attention to the possibility that the model may overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, both VGG and Lenet performed better in MINST data than in CIFAR10 data set. VGG neural network has more layers and is more complex, so the training effect will be better than Lenet. However, there may be overfitting problem, so we need to select appropriate hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
